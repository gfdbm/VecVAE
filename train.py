# -*- coding: utf-8 -*-
"""
Train VP-VAE (with file logging + preview export + train/val split)
- è®­ç»ƒæ—¥å¿—ï¼šCSV + JSONL
- è¿‡ç¨‹å¯è§†åŒ–ï¼šå®šæœŸæŠŠé¢„æµ‹è¿˜åŸä¸ºçŸ¢é‡å‘½ä»¤ï¼ˆtxt/pngï¼Œå¤šæ ·æœ¬ï¼‰
- æ•°æ®åˆ†å‰²ï¼šæ”¯æŒè®­ç»ƒé›†/éªŒè¯é›†éšæœºåˆ†å‰²ï¼ˆé»˜è®¤ 10% éªŒè¯é›†ï¼‰

å¯è§†åŒ–å¯¼å‡ºè¯´æ˜ï¼š
==============
1. åˆå§‹å¯è§†åŒ–ï¼ˆepoch 0ï¼‰ï¼š
   - ä¿å­˜æœªè®­ç»ƒæ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¾“å‡ºï¼Œç”¨äºå¯¹æ¯”
   - ä½ç½®: {out_dir}/eval_previews/preview_eval_ep0_*.{txt,png}

2. è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–ï¼ˆæ¯ export_every æ­¥ï¼‰ï¼š
   - ä¿å­˜è®­ç»ƒæ‰¹æ¬¡ï¼ˆè®­ç»ƒé›†ï¼‰çš„é¢„æµ‹ç»“æœ
   - é¢‘ç‡ï¼š--export-every å‚æ•°æ§åˆ¶ï¼ˆé»˜è®¤æ¯ 1000 æ­¥ï¼‰
   - ä½ç½®: {out_dir}/preview_train_ep{N}_step{M}_b{I}.{txt,png}

3. æ¯ä¸ª epoch è¯„ä¼°å¯è§†åŒ–ï¼š
   - ä¿å­˜éªŒè¯é›†æ ·æœ¬çš„é¢„æµ‹ç»“æœ
   - é¢‘ç‡ï¼š--eval-every å‚æ•°æ§åˆ¶ï¼ˆé»˜è®¤æ¯ 1 ä¸ª epochï¼Œæœ€åä¸€è½®æ€»ä¼šä¿å­˜ï¼‰
   - ä½ç½®: {out_dir}/eval_previews/preview_eval_ep{N}_*.{txt,png}

4. æœ€ç»ˆå¯è§†åŒ–ï¼ˆè®­ç»ƒç»“æŸï¼‰ï¼š
   - ä¿å­˜éªŒè¯é›† 16 ä¸ªæ ·æœ¬çš„æœ€ç»ˆé¢„æµ‹ç»“æœ
   - ä½ç½®: {out_dir}/eval_previews/preview_eval_ep999_*.{txt,png}

æ•°æ®åˆ†å‰²è¯´æ˜ï¼š
============
- ä½¿ç”¨ --val-split å‚æ•°æ§åˆ¶éªŒè¯é›†æ¯”ä¾‹ï¼ˆé»˜è®¤ 0.1 = 10%ï¼‰
- éšæœºåˆ†å‰²åŸºäº --seed å‚æ•°ï¼Œä¿è¯å¯å¤ç°
- è®­ç»ƒåªåœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œï¼Œè¯„ä¼°åªåœ¨éªŒè¯é›†ä¸Šè¿›è¡Œ
- PNG æ–‡ä»¶ä¸­ eval_previews æ–‡ä»¶å¤¹åŒ…å«çš„éƒ½æ˜¯éªŒè¯é›†æ ·æœ¬

å¯è§†åŒ–é¢‘ç‡æ§åˆ¶ï¼š
==============
- --export-every Nï¼šè®­ç»ƒè¿‡ç¨‹ä¸­æ¯ N æ­¥ä¿å­˜ä¸€æ¬¡è®­ç»ƒé›†é¢„è§ˆï¼ˆé»˜è®¤ 1000ï¼‰
- --eval-every Nï¼šæ¯ N ä¸ª epoch ä¿å­˜ä¸€æ¬¡éªŒè¯é›†é¢„è§ˆï¼ˆé»˜è®¤ 1ï¼‰
  ä¾‹å¦‚ï¼š--eval-every 5 è¡¨ç¤ºæ¯ 5 ä¸ª epoch ä¿å­˜ä¸€æ¬¡ PNG

ä½¿ç”¨è¯´æ˜ï¼š
- TXT æ–‡ä»¶ï¼šçº¯æ–‡æœ¬çŸ¢é‡å‘½ä»¤ï¼Œä¾¿äºè°ƒè¯•
- PNG æ–‡ä»¶ï¼šä½å›¾å›¾åƒï¼Œç›´æ¥æŸ¥çœ‹å­—ä½“æ¸²æŸ“æ•ˆæœï¼ˆç™½åº•é»‘å­—ï¼Œ512x512ï¼‰
"""

import os, sys, time, json, random, csv
from pathlib import Path
from contextlib import nullcontext
from datetime import datetime

import torch
import torch.nn.functional as F
from torch.amp import GradScaler, autocast  # æ–°æ¥å£ï¼Œæ›¿ä»£ torch.cuda.amp.*
from tqdm import tqdm, trange

# === è®©æ ¹ç›®å½•ä¸‹çš„ src/* å¯è¢«å¯¼å…¥ ===
PROJECT_ROOT = Path(__file__).resolve().parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

# === æ•°æ®ä¸å·¥å…· ===
from src.data.dataset import NPZDataset
from src.data.rsm_batcher import RSMBatcher, RSMConfig
from src.data.stage_renderer import StageRenderer, StageRendererConfig
from src.data.masks import build_loss_masks

# === æ¨¡å‹ ===
from src.model.encoder import VpVaeEncoder, VpVaeEncoderConfig
from src.model.decoder import Decoder, DecoderConfig

# === æŸå¤± ===
from src.losses.losses import compute_vae_losses, LossConfig, BetaWarmup

# === çŸ¢é‡å¯¼å‡ºï¼ˆè¿˜åŸå‘½ä»¤ + ä¿å­˜ï¼‰===
from src.utils.vec_export import decode_to_commands, save_commands_txt, save_commands_png


# ------------------------- å®ç”¨ï¼šæ—¥å¿—å™¨ -------------------------
class CsvLogger:
    """æŠŠè®­ç»ƒæŒ‡æ ‡è½åˆ° CSVï¼›é¦–æ¬¡å†™å…¥è¡¨å¤´ã€‚"""
    def __init__(self, path: Path, fieldnames):
        self.path = Path(path)
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self.fieldnames = list(fieldnames)
        if not self.path.exists():
            with self.path.open("w", newline="") as f:
                csv.writer(f).writerow(self.fieldnames)

    def write(self, row: dict):
        with self.path.open("a", newline="") as f:
            w = csv.writer(f)
            w.writerow([row.get(k, "") for k in self.fieldnames])


def append_jsonl(path: Path, obj: dict):
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("a", encoding="utf-8") as f:
        f.write(json.dumps(obj, ensure_ascii=False) + "\n")


# ------------------------- å…¶ä»–å°å·¥å…· -------------------------
def set_seed(seed: int = 42):
    random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)

def to_device_batch(items, device):
    """æŠŠä¸€æ‰¹æ ·æœ¬(list[dict])å †å å¹¶æ¬åˆ° deviceï¼›éå¼ é‡å­—æ®µä¿æŒåŸæ ·ï¼ˆåˆ—è¡¨ï¼‰ã€‚"""
    out = {}
    keys = list(items[0].keys())
    for k in keys:
        vals = [it[k] for it in items]
        out[k] = torch.stack(vals, 0).to(device) if torch.is_tensor(vals[0]) else vals
    return out

def render_stage_sdf_batch(renderer: StageRenderer, items, device):
    imgs = [renderer.render_item(it) for it in items]
    return torch.stack(imgs, 0).to(device)  # [B,1,H,W]

def save_ckpt(path, enc, dec, opt, scaler, step_epoch):
    path.parent.mkdir(parents=True, exist_ok=True)
    torch.save({
        "enc": enc.state_dict(),
        "dec": dec.state_dict(),
        "opt": opt.state_dict(),
        "scaler": scaler.state_dict() if scaler is not None else None,
        "step": step_epoch[0],
        "epoch": step_epoch[1],
    }, path)

def load_ckpt(path, enc, dec, opt=None, scaler=None, map_location="cpu"):
    ck = torch.load(path, map_location=map_location)
    enc.load_state_dict(ck["enc"], strict=True)
    dec.load_state_dict(ck["dec"], strict=True)
    if opt is not None and ck.get("opt") is not None:
        opt.load_state_dict(ck["opt"])
    if scaler is not None and ck.get("scaler") is not None:
        scaler.load_state_dict(ck["scaler"])
    return ck.get("step", 0), ck.get("epoch", 0)

def compute_class_weight_epoch(items, num_classes=9, device="cpu"):
    """
    å›ºå®šç±»åˆ«æƒé‡ï¼ˆåªç®—ä¸€æ¬¡ï¼‰ï¼šæŒ‰"å½“å‰è®­ç»ƒç®¡é“ï¼ˆå« RSMï¼‰"å…¨é‡éå†ï¼Œ
    ä»…ç»Ÿè®¡å‰ç¼€æœ‰æ•ˆä½ï¼ˆlmc=Trueï¼‰çš„å‘½ä»¤åˆ†å¸ƒ â†’ è®¡ç®— CE çš„ç±»åˆ«æƒé‡ã€‚
    ä¿®æ­£ï¼šbuild_loss_masks åœ¨å•æ ·æœ¬å¯èƒ½è¿”å› [1,L] æ©ç ï¼Œè¿™é‡ŒæŒ‰éœ€ squeeze ä¸€ä¸‹ã€‚
    """
    cnt = torch.zeros(num_classes, dtype=torch.float64)
    for it in tqdm(items, desc="Computing class weights", ncols=100):
        lmc, _, _ = build_loss_masks(it["seq_cmd"], it["seq_mask"])  # [L] æˆ– [1,L]
        if lmc.dim() == 2 and lmc.size(0) == 1:  # å•æ ·æœ¬è¿”å› [1,L] çš„æƒ…å†µ
            lmc = lmc.squeeze(0)
        ids = it["seq_cmd"][lmc.bool()]          # ä¸€ç»´å¸ƒå°”æ©ç ç´¢å¼•
        binc = torch.bincount(ids.cpu(), minlength=num_classes).to(cnt.dtype)
        cnt[:len(binc)] += binc
    inv = 1.0 / (cnt + 1e-3)
    w = inv * (num_classes / max(inv.sum().item(), 1.0))  # å½’ä¸€åˆ°å‡å€¼â‰ˆ1
    return w.to(device).float()

CMD_NAMES = ["PAD","M","L","Q","T","Z","NEW","HOLE","END"]


# ------------------------- å¯è§†åŒ–å¯¼å‡º -------------------------
def export_previews(out_dir: Path, prefix: str, step: int, epoch: int,
                    logits_cmd, pred_arg, seq_mask, items, max_n: int = 4):
    """
    æŠŠå½“å‰ batch çš„é¢„æµ‹è¿˜åŸä¸ºçŸ¢é‡å‘½ä»¤ï¼Œä¿å­˜ TXT+PNGã€‚
    - logits_cmd: [B,L,V]
    - pred_arg:   [B,L,4]
    - seq_mask:   [B,L]
    - items:      åŸ batch çš„ list[dict]ï¼ˆä¸ºäº†å– norm åšåå½’ä¸€åŒ–ï¼‰
    """
    out_dir.mkdir(parents=True, exist_ok=True)
    B = logits_cmd.size(0)
    n = min(max_n, B)
    # å¯é€‰ï¼šåå½’ä¸€åŒ–å‚æ•° (s, tx, ty)
    norms = None
    if "norm" in items[0]:
        import numpy as np
        norms = np.stack([it["norm"].cpu().numpy() for it in items], 0)  # [B,3]
    # è¿˜åŸå‘½ä»¤ï¼ˆå†…éƒ¨åš arg é—¨æ§ + å– argmaxï¼‰
    cmds_list = decode_to_commands(
        logits_cmd.cpu(), pred_arg.cpu(), seq_mask.cpu(), norms=norms
    )
    for i in range(n):
        tag = f"{prefix}_ep{epoch}_step{step}_b{i}"
        txt = out_dir / f"preview_{tag}.txt"
        png = out_dir / f"preview_{tag}.png"
        save_commands_txt(str(txt), cmds_list[i])
        save_commands_png(str(png), cmds_list[i], size=512, stroke=False, fill=True, 
                         stroke_width=1.5, bg_color=(255,255,255,255), fg_color=(0,0,0,255))


# ------------------------- è®­ç»ƒ / è¯„ä¼° -------------------------
def train_one_epoch(ds, renderer, enc, dec, opt, scaler, loss_cfg, beta_sched,
                    batch_size, device, log_every, grad_clip=1.0,
                    export_every=None, out_dir=None, step0=0,
                    class_weight=None, epoch_idx=0,
                    csv_logger: CsvLogger = None, jsonl_path: Path = None,
                    preview_n: int = 4):
    enc.train(); dec.train()
    n = len(ds)
    indices = torch.randperm(n).tolist()
    t0 = time.time()
    running = {"loss": 0.0, "ce": 0.0, "l1": 0.0, "kl": 0.0}
    step = step0

    # åˆ›å»ºè¿›åº¦æ¡
    pbar = tqdm(range(0, n, batch_size), 
                desc=f"Epoch {epoch_idx}", 
                ncols=120,
                bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')
    
    for s in pbar:
        step += 1
        idxs = indices[s: s + batch_size]
        items = [ds[i] for i in idxs]
        batch = to_device_batch(items, device)
        stage_sdf = render_stage_sdf_batch(renderer, items, device)  # [B,1,H,W]

        seq_cmd, seq_arg = batch["seq_cmd"], batch["seq_arg"]
        seq_mask = batch["seq_mask"].bool()
        contour_ids, seq_topo = batch["contour_ids"], batch["seq_topo"]

        loss_cfg.beta = beta_sched.step()
        opt.zero_grad(set_to_none=True)

        use_cuda_amp = (scaler is not None and device.type == "cuda")
        with (autocast("cuda", dtype=torch.float16) if use_cuda_amp else nullcontext()):
            # ç¼–ç å™¨ï¼šå‰ç¼€ + åƒç´ æ¡ä»¶ â†’ Î¼/logÏƒ â†’ é‡‡æ · z
            mu, logvar, z, _ = enc(
                seq_cmd, seq_arg, seq_mask, contour_ids, seq_topo, stage_sdf,
                sample=True, eps_std=1.0
            )
            # è§£ç å™¨ï¼šz + åƒç´ æ¡ä»¶ â†’ é¢„æµ‹å‘½ä»¤/åæ ‡
            logits_cmd, pred_arg, _ = dec(z, stage_sdf, seq_mask)

            # åŸºç¡€æŸå¤±
            total, stats = compute_vae_losses(
                logits_cmd, pred_arg, mu, logvar, seq_cmd, seq_arg, seq_mask, cfg=loss_cfg
            )
            # ç”¨å›ºå®šç±»åˆ«æƒé‡æ›¿æ¢ CEï¼ˆåªå½±å“ CEï¼›L1/KL ä¸å˜ï¼‰
            if class_weight is not None:
                lmc, _, _ = build_loss_masks(seq_cmd, seq_mask)  # [B,L]
                ce = F.cross_entropy(
                    logits_cmd[lmc], seq_cmd[lmc],
                    weight=class_weight, reduction="mean"
                ) if lmc.any() else torch.zeros([], device=total.device)
                # âœ… ä¿®å¤ï¼šæ­£ç¡®åº”ç”¨é…ç½®çš„æŸå¤±æƒé‡
                total = loss_cfg.ce_weight * ce + loss_cfg.l1_weight * stats["loss_l1"].to(total.device) + loss_cfg.beta * stats["loss_kl"].to(total.device)
                stats["loss_ce"] = ce.detach()
                stats["loss_total"] = total.detach()

        # åä¼  + æ›´æ–°
        if scaler is not None and device.type == "cuda":
            scaler.scale(total).backward()
            if grad_clip and grad_clip > 0:
                scaler.unscale_(opt)
                torch.nn.utils.clip_grad_norm_(list(enc.parameters()) + list(dec.parameters()), grad_clip)
            scaler.step(opt); scaler.update()
        else:
            total.backward()
            if grad_clip and grad_clip > 0:
                torch.nn.utils.clip_grad_norm_(list(enc.parameters()) + list(dec.parameters()), grad_clip)
            opt.step()

        # ç´¯è®¡
        running["loss"] += float(stats["loss_total"])
        running["ce"]  += float(stats["loss_ce"])
        running["l1"]  += float(stats["loss_l1"])
        running["kl"]  += float(stats["loss_kl"])

        # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤ºï¼ˆå®æ—¶æ˜¾ç¤ºæœ€æ–°æŸå¤±ï¼‰
        pbar.set_postfix({
            'loss': f"{running['loss']/max(1, step-step0):.4f}",
            'CE': f"{running['ce']/max(1, step-step0):.4f}",
            'L1': f"{running['l1']/max(1, step-step0):.4f}",
            'KL': f"{running['kl']/max(1, step-step0):.4f}",
            'Î²': f"{loss_cfg.beta:.3f}"
        })

        # æ‰“å° + è½ç›˜æ—¥å¿—
        if step % log_every == 0:
            it_time = (time.time() - t0) / max(1, log_every)
            ips = 1.0 / it_time
            lr = opt.param_groups[0]["lr"]
            msg = (f"[train] ep={epoch_idx} step={step}  "
                   f"loss={running['loss']/log_every:.4f}  "
                   f"CE={running['ce']/log_every:.4f}  "
                   f"L1={running['l1']/log_every:.4f}  "
                   f"KL={running['kl']/log_every:.4f}  "
                   f"beta={loss_cfg.beta:.3f}  lr={lr:.2e}  {it_time:.2f}s/it")
            pbar.write(msg)  # ä½¿ç”¨ tqdm.write è€Œä¸æ˜¯ printï¼Œé¿å…å¹²æ‰°è¿›åº¦æ¡

            # CSV
            if csv_logger is not None:
                csv_logger.write({
                    "time": datetime.now().isoformat(timespec="seconds"),
                    "epoch": epoch_idx,
                    "step": step,
                    "loss": round(running['loss']/log_every, 6),
                    "ce": round(running['ce']/log_every, 6),
                    "l1": round(running['l1']/log_every, 6),
                    "kl": round(running['kl']/log_every, 6),
                    "beta": round(loss_cfg.beta, 6),
                    "lr": lr,
                    "ips": ips,
                })
            # JSONL
            if jsonl_path is not None:
                append_jsonl(jsonl_path, {
                    "time": datetime.now().isoformat(timespec="seconds"),
                    "epoch": epoch_idx, "step": step,
                    "loss": running['loss']/log_every,
                    "ce": running['ce']/log_every,
                    "l1": running['l1']/log_every,
                    "kl": running['kl']/log_every,
                    "beta": float(loss_cfg.beta), "lr": float(lr), "ips": ips,
                })

            t0 = time.time()
            running = {"loss": 0.0, "ce": 0.0, "l1": 0.0, "kl": 0.0}

        # å¯è§†åŒ–å¯¼å‡ºï¼šç”¨ Î¼ è§£ç æ›´ç¨³
        if export_every and out_dir and (step % export_every == 0):
            enc.eval(); dec.eval()
            with torch.no_grad():
                logits_cmd_, pred_arg_, _ = dec(mu, stage_sdf, seq_mask)  # ç”¨ Î¼
                export_previews(out_dir, "train", step, epoch_idx,
                                logits_cmd_, pred_arg_, seq_mask, items, max_n=preview_n)
                pbar.write(f"[export] saved previews at step {step} (N={min(preview_n, len(items))})")
            enc.train(); dec.train()

    pbar.close()  # å…³é—­è¿›åº¦æ¡
    return step


@torch.no_grad()
def evaluate(ds, renderer, enc, dec, loss_cfg, batch_size, device, 
             export_vis=False, out_dir=None, epoch_idx=0, preview_n=4):
    """è¯„ä¼°å‡½æ•°ï¼Œå¯é€‰æ‹©å¯¼å‡ºå¯è§†åŒ–
    
    Args:
        export_vis: æ˜¯å¦å¯¼å‡ºå¯è§†åŒ–ç»“æœ
        out_dir: è¾“å‡ºç›®å½•
        epoch_idx: å½“å‰ epoch ç¼–å·
        preview_n: å¯¼å‡ºçš„æ ·æœ¬æ•°é‡
    """
    enc.eval(); dec.eval()
    n = len(ds)
    indices = list(range(0, min(n, batch_size)))
    items = [ds[i] for i in indices]
    batch = to_device_batch(items, device)
    stage_sdf = render_stage_sdf_batch(renderer, items, device)

    seq_cmd, seq_arg = batch["seq_cmd"], batch["seq_arg"]
    seq_mask = batch["seq_mask"].bool()
    contour_ids, seq_topo = batch["contour_ids"], batch["seq_topo"]

    mu, logvar, z, _ = enc(seq_cmd, seq_arg, seq_mask, contour_ids, seq_topo, stage_sdf, sample=False)
    logits_cmd, pred_arg, _ = dec(z, stage_sdf, seq_mask)
    total, stats = compute_vae_losses(
        logits_cmd, pred_arg, mu, logvar, seq_cmd, seq_arg, seq_mask, cfg=loss_cfg
    )
    
    # å¯¼å‡ºéªŒè¯é›†å¯è§†åŒ–
    if export_vis and out_dir:
        export_previews(out_dir / "eval_previews", "eval", 0, epoch_idx,
                       logits_cmd, pred_arg, seq_mask, items, max_n=preview_n)
        print(f"[eval export] saved {min(preview_n, len(items))} evaluation previews to {out_dir / 'eval_previews'}")
    
    return {k: float(v) for k, v in stats.items()}


# --------------------------- main ------------------------
def main():
    import sys
    from config import get_config, list_configs
    
    # æ£€æŸ¥æ˜¯å¦è¯·æ±‚åˆ—å‡ºé…ç½®
    if '--list-configs' in sys.argv:
        list_configs()
        return
    
    # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†é…ç½®é¢„è®¾
    config_name = 'high_quality'  # é»˜è®¤ä½¿ç”¨é«˜è´¨é‡é…ç½®ï¼ˆé’ˆå¯¹å¤§æ•°æ®é›†ï¼‰
    
    if '--config' in sys.argv:
        idx = sys.argv.index('--config')
        if idx + 1 < len(sys.argv):
            config_name = sys.argv[idx + 1]
            # ç§»é™¤ --config åŠå…¶å€¼ï¼Œå‰©ä½™çš„ç”¨äºè¦†ç›–
            cmd_args = sys.argv[1:idx] + sys.argv[idx+2:]
        else:
            print("é”™è¯¯: --config éœ€è¦æŒ‡å®šé…ç½®åç§°")
            print("å¯ç”¨é…ç½®: default, balanced, high_quality, memory_limited")
            print("ä½¿ç”¨ --list-configs æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯")
            return
    else:
        # æ²¡æœ‰æŒ‡å®š --configï¼Œä½¿ç”¨æ‰€æœ‰å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
        cmd_args = sys.argv[1:]
    
    # åŠ è½½é…ç½®
    try:
        if cmd_args:
            args = get_config(config_name, cmd_args)
        else:
            args = get_config(config_name)
    except ValueError as e:
        print(f"é…ç½®é”™è¯¯: {e}")
        print("\nå¯ç”¨é…ç½®:")
        list_configs()
        return
    
    # æ‰“å°å®Œæ•´çš„è®­ç»ƒé…ç½®
    print("\n" + "="*80)
    print(f"ğŸ“‹ è®­ç»ƒé…ç½®: {config_name.upper()}")
    print("="*80)
    
    # æ•°æ®é…ç½®
    print("\nğŸ“‚ æ•°æ®é…ç½®:")
    print(f"  æ•°æ®é›†è·¯å¾„:     {args.npz}")
    print(f"  ä½¿ç”¨ RSM:       {'æ˜¯ âœ“' if args.use_rsm else 'å¦'}")
    print(f"  éªŒè¯é›†æ¯”ä¾‹:     {args.val_split * 100:.1f}%")
    if args.img_size:
        print(f"  å›¾åƒå¤§å°:       {args.img_size}Ã—{args.img_size}")
    
    # æ¨¡å‹æ¶æ„
    print("\nğŸ—ï¸  æ¨¡å‹æ¶æ„:")
    print(f"  åµŒå…¥ç»´åº¦ (embed):           {args.embed}")
    print(f"  æ½œåœ¨ç©ºé—´ç»´åº¦ (zdim):        {args.zdim}")
    print(f"  æ³¨æ„åŠ›å¤´æ•° (heads):         {args.heads}")
    print(f"  Patch å¤§å°:                 {args.patch}")
    print(f"  çŸ¢é‡ç¼–ç å™¨å±‚æ•° (vec):       {args.vec_layers}")
    print(f"  è·¨æ³¨æ„åŠ›å±‚æ•° (enc_xlayers): {args.enc_xlayers}")
    print(f"  è§£ç å™¨å±‚æ•° (dec_layers):    {args.dec_layers}")
    
    # è®­ç»ƒè¶…å‚æ•°
    print("\nâš™ï¸  è®­ç»ƒè¶…å‚æ•°:")
    print(f"  è®­ç»ƒè½®æ¬¡ (epochs):  {args.epochs}")
    print(f"  æ‰¹æ¬¡å¤§å° (batch):   {args.batch}")
    print(f"  å­¦ä¹ ç‡ (lr):        {args.lr:.6f}")
    print(f"  æƒé‡è¡°å‡ (wd):      {args.wd}")
    print(f"  æ¢¯åº¦è£å‰ª:           {args.grad_clip}")
    print(f"  éšæœºç§å­:           {args.seed}")
    
    # æŸå¤±æƒé‡é…ç½®
    print("\nğŸ“Š æŸå¤±æƒé‡é…ç½®:")
    print(f"  L1 æƒé‡:            {args.l1_weight}")
    print(f"  CE æƒé‡:            {args.ce_weight}")
    print(f"  Beta é¢„çƒ­æ­¥æ•°:      {args.beta_warmup:,}")
    print(f"  Free Bits:          {args.free_bits}")
    
    # æ—¥å¿—å’Œä¿å­˜
    print("\nğŸ’¾ æ—¥å¿—å’Œä¿å­˜:")
    print(f"  è¾“å‡ºç›®å½•:           {args.out}")
    print(f"  æ—¥å¿—é¢‘ç‡:           æ¯ {args.log_every} æ­¥")
    print(f"  è¯„ä¼°é¢‘ç‡:           æ¯ {args.eval_every} ä¸ª epoch")
    print(f"  å¯¼å‡ºé¢„è§ˆé¢‘ç‡:       æ¯ {args.export_every:,} æ­¥")
    print(f"  é¢„è§ˆæ ·æœ¬æ•°:         {args.preview_n}")
    if args.resume:
        print(f"  æ¢å¤æ£€æŸ¥ç‚¹:         {args.resume}")
    
    print("="*80 + "\n")

    # ---- åŸºç¡€åˆå§‹åŒ– ----
    set_seed(args.seed)
    device = torch.device(args.device)
    out_dir = Path(args.out); (out_dir / "ckpt").mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
    import json
    config_dict = vars(args)
    config_dict['config_name'] = config_name
    with open(out_dir / "training_config.json", "w", encoding="utf-8") as f:
        json.dump(config_dict, f, indent=2, ensure_ascii=False)
    print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {out_dir / 'training_config.json'}\n")
    
    # æ‰“å°è®¾å¤‡ä¿¡æ¯
    print("\n" + "="*80)
    print("ğŸ–¥ï¸  è®¾å¤‡ä¿¡æ¯")
    print("="*80)
    if device.type == "cuda":
        print(f"âœ… ä½¿ç”¨ GPU è®­ç»ƒ")
        print(f"   è®¾å¤‡: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜æ€»é‡: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        if torch.cuda.is_available():
            print(f"   CUDA ç‰ˆæœ¬: {torch.version.cuda}")
            print(f"   å¯ç”¨ GPU æ•°é‡: {torch.cuda.device_count()}")
    else:
        print(f"âš ï¸  ä½¿ç”¨ CPU è®­ç»ƒï¼ˆé€Ÿåº¦ä¼šå¾ˆæ…¢ï¼‰")
        print(f"   å»ºè®®: å¦‚æœæœ‰ GPUï¼Œè¯·ä½¿ç”¨ --device cuda")
    print(f"   æ··åˆç²¾åº¦ (AMP): {'å¯ç”¨ âœ“' if args.amp else 'ç¦ç”¨'}")
    print(f"   éšæœºç§å­: {args.seed}")
    print("="*80 + "\n")

    # æ—¥å¿—æ–‡ä»¶
    csv_logger = CsvLogger(out_dir / "train_log.csv",
                           fieldnames=["time","epoch","step","loss","ce","l1","kl","beta","lr","ips"])
    jsonl_path = out_dir / "events.jsonl"

    # ---- æ•°æ®ï¼šNPZ + RSMï¼ˆå¯é€‰ï¼‰----
    base = NPZDataset(args.npz, mmap=True, use_seq_topo=True, strict_shapes=True)
    if args.use_rsm:
        ds = RSMBatcher(base, RSMConfig(
            rsm_stages=(0.25, 0.5, 0.75, 1.0),
            rsm_probs=(0.15, 0.25, 0.25, 0.35),
            enforce_contour_ids=True,
            allow_token_prefix_fallback=False,
        ))
        print("[info] dataset: RSM mode")
    else:
        ds = base
        print("[info] dataset: FULL (no RSM)")

    renderer = StageRenderer(StageRendererConfig(
        img_size=args.img_size or base.H,
        sdf_clip_px=8.0,
        out_dtype=torch.float32,
    ))

    # ---- è®­ç»ƒ/éªŒè¯é›†åˆ†å‰² ----
    n_total = len(ds)
    if args.val_split > 0 and args.val_split < 1.0:
        n_val = max(1, int(n_total * args.val_split))  # è‡³å°‘1ä¸ªéªŒè¯æ ·æœ¬
        n_train = n_total - n_val
        
        # éšæœºæ‰“ä¹±ç´¢å¼•ï¼ˆä½¿ç”¨å›ºå®šç§å­ä¿è¯å¯å¤ç°ï¼‰
        rng = random.Random(args.seed)
        indices = list(range(n_total))
        rng.shuffle(indices)
        
        train_indices = sorted(indices[:n_train])  # æ’åºä»¥ä¿æŒåŸå§‹é¡ºåºï¼ˆå¯é€‰ï¼‰
        val_indices = sorted(indices[n_train:])
        
        # åˆ›å»ºæ•°æ®é›†åŒ…è£…å™¨
        from torch.utils.data import Subset
        train_ds = Subset(ds, train_indices)
        val_ds = Subset(ds, val_indices)
        
        print(f"[æ•°æ®åˆ†å‰²] æ€»æ ·æœ¬: {n_total}, è®­ç»ƒé›†: {n_train} ({100*(1-args.val_split):.1f}%), éªŒè¯é›†: {n_val} ({100*args.val_split:.1f}%)")
        print(f"[æ•°æ®åˆ†å‰²] éªŒè¯é›†ç´¢å¼•: {val_indices[:min(10, len(val_indices))]}" + 
              (f"... (å…±{len(val_indices)}ä¸ª)" if len(val_indices) > 10 else ""))
    else:
        # ä¸åˆ†å‰²ï¼Œæ‰€æœ‰æ•°æ®ç”¨äºè®­ç»ƒ
        train_ds = ds
        val_ds = ds
        print(f"[æ•°æ®åˆ†å‰²] ä¸ä½¿ç”¨éªŒè¯é›†ï¼Œæ‰€æœ‰ {n_total} ä¸ªæ ·æœ¬ç”¨äºè®­ç»ƒ")

    # ---- æ¨¡å‹ ----
    enc = VpVaeEncoder(VpVaeEncoderConfig(
        embed_dim=args.embed, num_heads=args.heads, cross_layers=args.enc_xlayers,
        patch_size=args.patch, z_dim=args.zdim, vec_layers=args.vec_layers,
        use_prefix_repr=True, dropout=0.0
    )).to(device)

    dec = Decoder(DecoderConfig(
        vocab_size=9, max_len=base.L, embed_dim=args.embed, z_dim=args.zdim,
        n_heads=args.heads, n_layers=args.dec_layers, patch_size=args.patch, use_pixel_cross_attn=True
    )).to(device)

    # ---- ä¼˜åŒ– / AMP / KL é¢„çƒ­ ----
    opt = torch.optim.AdamW(list(enc.parameters()) + list(dec.parameters()), lr=args.lr, weight_decay=args.wd)
    scaler = GradScaler("cuda") if (args.amp and device.type == "cuda") else None
    beta_sched = BetaWarmup(warmup_steps=args.beta_warmup, target=1.0)

    loss_cfg = LossConfig(
        beta=0.0, free_bits=args.free_bits,
        use_class_weight=False,  # æˆ‘ä»¬ç”¨å›ºå®šæƒé‡æ›¿æ¢ CE
        num_classes=9,
        l1_weight=args.l1_weight,
        ce_weight=args.ce_weight
    )

    # ---- å›ºå®šç±»åˆ«æƒé‡ï¼šè‹¥å·²å­˜åœ¨åˆ™åŠ è½½ï¼Œå¦åˆ™åœ¨è®­ç»ƒé›†ä¸Šç»Ÿè®¡ä¸€æ¬¡å¹¶ä¿å­˜ ----
    cw_path = out_dir / "class_weight.pt"
    if cw_path.is_file():
        class_weight = torch.load(cw_path, map_location="cpu").to(device)
        print("[weight] loaded fixed class weights from:", cw_path)
    else:
        print("[weight] computing FIXED class weights (one-time, train set only, with current RSM setting)...")
        indices_all = list(range(len(train_ds)))
        class_weight = compute_class_weight_epoch([train_ds[i] for i in indices_all], num_classes=9, device=device)
        torch.save(class_weight.cpu(), cw_path)
        pretty = {CMD_NAMES[i] if i < len(CMD_NAMES) else i: float(class_weight[i]) for i in range(len(class_weight))}
        print("[weight] class_weight =", pretty)

    # ---- æ–­ç‚¹æ¢å¤ï¼ˆå¯é€‰ï¼‰----
    global_step, start_epoch = 0, 0
    if args.resume and Path(args.resume).is_file():
        global_step, start_epoch = load_ckpt(Path(args.resume), enc, dec, opt=opt, scaler=scaler, map_location=device)
        print(f"[resume] from {args.resume} @ step={global_step} epoch={start_epoch}")

    # ---- åˆå§‹å¯è§†åŒ–ï¼šå¯¼å‡ºæœªè®­ç»ƒæ¨¡å‹çš„è¾“å‡ºï¼ˆä»…åœ¨ä»å¤´å¼€å§‹è®­ç»ƒæ—¶ï¼‰----
    if start_epoch == 0:
        print("\n[åˆå§‹å¯è§†åŒ–] å¯¼å‡ºæœªè®­ç»ƒæ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„é¢„æµ‹ç»“æœ...")
        initial_eval = evaluate(val_ds, renderer, enc, dec, loss_cfg, 
                               batch_size=args.batch, device=device,
                               export_vis=True, out_dir=out_dir, 
                               epoch_idx=0, preview_n=args.preview_n)
        print(f"[åˆå§‹çŠ¶æ€-éªŒè¯é›†] loss={initial_eval['loss_total']:.4f}  "
              f"CE={initial_eval['loss_ce']:.4f}  "
              f"L1={initial_eval['loss_l1']:.4f}  "
              f"KL={initial_eval['loss_kl']:.4f}")
        with open(out_dir / "initial_eval.json", "w", encoding="utf-8") as f:
            json.dump(initial_eval, f, indent=2)

    # ---- è®­ç»ƒå¾ªç¯ ----
    for epoch in trange(start_epoch, args.epochs, desc="Training", ncols=100):
        print(f"\n==> epoch {epoch+1}/{args.epochs}")
        global_step = train_one_epoch(
            train_ds, renderer, enc, dec, opt, scaler, loss_cfg, beta_sched,
            batch_size=args.batch, device=device, log_every=args.log_every,
            grad_clip=args.grad_clip, export_every=args.export_every, out_dir=out_dir,
            step0=global_step, class_weight=class_weight, epoch_idx=epoch+1,
            csv_logger=csv_logger, jsonl_path=jsonl_path, preview_n=args.preview_n
        )
        # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼° + æŒ‰é¢‘ç‡å¯¼å‡ºå¯è§†åŒ–
        should_export = ((epoch + 1) % args.eval_every == 0) or (epoch + 1 == args.epochs)
        eval_stats = evaluate(val_ds, renderer, enc, dec, loss_cfg, 
                             batch_size=args.batch, device=device,
                             export_vis=should_export, out_dir=out_dir, 
                             epoch_idx=epoch+1, preview_n=args.preview_n)
        print(f"[éªŒè¯é›†] loss={eval_stats['loss_total']:.4f}  CE={eval_stats['loss_ce']:.4f}  "
              f"L1={eval_stats['loss_l1']:.4f}  KL={eval_stats['loss_kl']:.4f}" + 
              (f"  [å·²ä¿å­˜PNG]" if should_export else ""))
        with open(out_dir / "last_eval.json", "w", encoding="utf-8") as f:
            json.dump(eval_stats, f, indent=2)

        # ä¿å­˜ ckpt
        ck_path = out_dir / "ckpt" / f"epoch{epoch+1}.pt"
        save_ckpt(ck_path, enc, dec, opt, scaler, (global_step, epoch+1))
        print(f"[ckpt] saved {ck_path}")

    # ---- è®­ç»ƒå®Œæˆï¼šæœ€ç»ˆå¯è§†åŒ–æ€»ç»“ ----
    print("\n" + "="*80)
    print("è®­ç»ƒå®Œæˆï¼ç”ŸæˆéªŒè¯é›†æœ€ç»ˆå¯è§†åŒ–æ€»ç»“...")
    print("="*80)
    
    # å¯¼å‡ºæ›´å¤šéªŒè¯é›†æ ·æœ¬çš„æœ€ç»ˆç»“æœ
    final_preview_n = min(16, len(val_ds))  # æœ€å¤šå¯¼å‡º16ä¸ªæ ·æœ¬
    final_eval = evaluate(val_ds, renderer, enc, dec, loss_cfg, 
                         batch_size=final_preview_n, device=device,
                         export_vis=True, out_dir=out_dir, 
                         epoch_idx=999, preview_n=final_preview_n)
    
    print(f"\n[æœ€ç»ˆè¯„ä¼°-éªŒè¯é›†] loss={final_eval['loss_total']:.4f}  "
          f"CE={final_eval['loss_ce']:.4f}  "
          f"L1={final_eval['loss_l1']:.4f}  "
          f"KL={final_eval['loss_kl']:.4f}")
    
    with open(out_dir / "final_eval.json", "w", encoding="utf-8") as f:
        json.dump(final_eval, f, indent=2)
    
    print(f"\nâœ… æ‰€æœ‰å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°ï¼š")
    print(f"   ğŸ“Š è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_ds)}")
    print(f"   ğŸ“Š éªŒè¯é›†æ ·æœ¬æ•°: {len(val_ds)}")
    print(f"   - è®­ç»ƒè¿‡ç¨‹é¢„è§ˆï¼ˆè®­ç»ƒé›†ï¼‰: {out_dir}")
    print(f"   - è¯„ä¼°é¢„è§ˆï¼ˆéªŒè¯é›†ï¼‰: {out_dir / 'eval_previews'}")
    print(f"   - æ£€æŸ¥ç‚¹: {out_dir / 'ckpt'}")
    print(f"   - æ—¥å¿—: {out_dir / 'train_log.csv'} å’Œ {out_dir / 'events.jsonl'}")

if __name__ == "__main__":
    main()
